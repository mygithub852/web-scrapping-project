{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product vertical\n",
    "from www.amazon.in. The product verticals to be searched will be taken as input from user.\n",
    "For e.g. If user input is ‘guitar’. Then search for guitars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "from seleniu\n",
    "m.common.exceptions import ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_xpath('//input[@class=\"nav-input nav-progressive-attribute\"]')\n",
    "search_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inp = input('Enter the product you want to search : ')\n",
    "search_bar.send_keys(user_inp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages \n",
    "of your search results and save it in a data frame and csv. In case if any product vertical has \n",
    "less than 3 pages in search results then scrape all the products available under that product \n",
    "vertical. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of \n",
    "Ratings\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" \n",
    "and “Product URL”. In case, if any of the details are missing for any of the product then \n",
    "replace it by “-“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "product_title=[]\n",
    "product_rating=[]\n",
    "product_no_of_rating=[]\n",
    "product_price=[]\n",
    "abailability=[]\n",
    "other_details=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the product_title\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        product_title.append(\"--\") \n",
    "    else:\n",
    "        product_title.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the rating\n",
    "rating=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in rating:\n",
    "    if i.text is None :\n",
    "        product_rating.append(\"--\") \n",
    "    else:\n",
    "        product_rating.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the no_of_rating\n",
    "no_of_rating=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in no_of_rating:\n",
    "    if i.text is None :\n",
    "        product_no_of_rating.append(\"--\") \n",
    "    else:\n",
    "        product_no_of_rating.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the price\n",
    "price=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in product_price:\n",
    "    if i.text is None :\n",
    "        product_price.append(\"--\") \n",
    "    else:\n",
    "        product_price.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Abailability\n",
    "Abailability=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Abailability:\n",
    "    if i.text is None :\n",
    "        abailability.append(\"--\") \n",
    "    else:\n",
    "        abailability.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Other_details\n",
    "Other_details=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Other_details:\n",
    "    if i.text is None :\n",
    "        other_details.append(\"--\") \n",
    "    else:\n",
    "        other_detailse.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Url\n",
    "Url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Url:\n",
    "    if i.text is None :\n",
    "        URL.append(\"--\") \n",
    "    else:\n",
    "        URL.append(i.get_attribute(\"href\"))\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_title=[]\n",
    "product_rating=[]\n",
    "product_no_of_rating=[]\n",
    "product_price=[]\n",
    "abailability=[]\n",
    "other_details=[]\n",
    "URL=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'product_title':product_title[:100],'product_rating': product_rating[:100],'no of rating': product_no_of_rating[:100],'price':product_price[:100],'abailability': abailability[:100],'other details':other_details[:100],'url':URL[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and \n",
    "scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://images.google.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car=driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]')\n",
    "Car=[]\n",
    "for i in car:\n",
    "    Car.append(i.get_attribute(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_learning=driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]')\n",
    "machine_learning=[]\n",
    "for i in Machine_learning:\n",
    "    machine_learning.append(i.get_attribute(\"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on \n",
    "google maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION-5\n",
    "#Performing Geolocation Testing With Selenium Using Python For Selenium Test Automation\n",
    "import pytest\n",
    "import pytest_html\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from time import sleep\n",
    "import sys\n",
    "import urllib3\n",
    "import warnings\n",
    " \n",
    "class Test_Scenario_1:\n",
    "    def test_1(self):\n",
    "        driver = webdriver.Chrome()\n",
    " \n",
    "        self.latitude = 42.1408845\n",
    "        self.longitude = -72.5033907\n",
    "        self.accuracy = 100\n",
    " \n",
    "        driver.maximize_window()\n",
    "        driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", {\n",
    "            \"latitude\": self.latitude,\n",
    "            \"longitude\": self.longitude,\n",
    "            \"accuracy\": self.accuracy\n",
    "    })\n",
    " \n",
    "        driver.get(\"https://locations.dennys.com/search.html/\")\n",
    " \n",
    "        time.sleep(10)\n",
    "       \n",
    "        location_icon = driver.find_element_by_css_selector(\".icon-geolocate\")\n",
    "        time.sleep(10)\n",
    "        location_icon.click()\n",
    " \n",
    "        time.sleep(10)\n",
    "        print(\"Geolocation testing with Selenium is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://locations.dennys.com/search.html/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute_cdp_cmd for Geolocation testing with Selenium\n",
    "self.latitude = 42.1408845\n",
    "self.longitude = -72.5033907\n",
    "self.accuracy = 100\n",
    " \n",
    "driver.maximize_window()\n",
    "driver.execute_cdp_cmd(\"Emulation.setGeolocationOverride\", {\n",
    "\t\"latitude\": self.latitude,\n",
    "      \"longitude\": self.longitude,\n",
    "      \"accuracy\": self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_icon = driver.find_element_by_css_selector(\".icon-geolocate\")\n",
    "time.sleep(10)\n",
    "location_icon.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytest -v Mocking_geolocation_Selenium_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a python program to scrape the details for all billionaires from www.forbes.com. \n",
    "Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, \n",
    "“Industry”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.forbes.com/billionaires/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.forbes.com/billionaires/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "rank=[]\n",
    "name=[]\n",
    "age=[]\n",
    "net_worth=[]\n",
    "country=[]\n",
    "source=[]\n",
    "industry=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the rank\n",
    "Rank=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Rank:\n",
    "    if i.text is None :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the name\n",
    "Name=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Name:\n",
    "    if i.text is None :\n",
    "        name.append(\"--\") \n",
    "    else:\n",
    "        name.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Age\n",
    "Age=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Age:\n",
    "    if i.text is None :\n",
    "        age.append(\"--\") \n",
    "    else:\n",
    "        age.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Net_worth\n",
    "Net_worth=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Net_worth:\n",
    "    if i.text is None :\n",
    "        net_worth.append(\"--\") \n",
    "    else:\n",
    "        net_worth.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Source\n",
    "Source=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Source:\n",
    "    if i.text is None :\n",
    "        source.append(\"--\") \n",
    "    else:\n",
    "        sourcee.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Industry\n",
    "Industry=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Industry:\n",
    "    if i.text is None :\n",
    "        industry.append(\"--\") \n",
    "    else:\n",
    "        industry.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Country\n",
    "Country=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Country:\n",
    "    if i.text is None :\n",
    "        country.append(\"--\") \n",
    "    else:\n",
    "        country.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'rank':rank[:100],'name':name[:100],'age': age[:100],'net_worth':net_worth[:100],'country': country[:100],'source':source[:100],'industry':industry[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a program to extract at least 500 Comments, Comment upvote and time when comment \n",
    "was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION-9\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome \n",
    "youtube_pages = \"https://www.youtube.com/\"\n",
    "locationOfWebdriver = \"C:/Users/User/Downloads/chromedriver_win32/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(locationOfWebdriver)\n",
    "driver.get(youtube_pages)\n",
    "time.sleep(10)\n",
    "try:\n",
    "    print(\"=\" * 40)  # Shows in terminal when youtube summary page with search keyword is being scraped\n",
    "    print(\"Scraping \" + youtube_pages)\n",
    "    search = driver.find_element_by_id('search')\n",
    "    search.send_keys(\"Kishore Kumar\")    \n",
    "    driver.find_element_by_id('search-icon-legacy').click()\n",
    "    time.sleep(20)    \n",
    "    vtitle = driver.find_elements_by_id('video-title')\n",
    "    subscription = driver.find_elements_by_id('byline')\n",
    "    views = driver.find_elements_by_xpath('//div[@id=\"metadata-line\"]/span[1]')\n",
    "    posted = driver.find_elements_by_xpath('//div[@id=\"metadata-line\"]/span[2]')\n",
    "    \n",
    "    tcount = 0\n",
    "    href = []\n",
    "    title = []\n",
    "    channel = []\n",
    "    numview = []\n",
    "    postdate = []\n",
    "        \n",
    "    while tcount < 10:\n",
    "        href.append(vtitle[tcount].get_attribute('href'))\n",
    "        channel.append(subscription[tcount].get_attribute('title'))\n",
    "        title.append(vtitle[tcount].text)\n",
    "        numview.append(views[tcount].text)\n",
    "        postdate.append(posted[tcount].text)  \n",
    "        tcount = tcount +1\n",
    "    \n",
    "    # launch top ten extracted links and extract comment details\n",
    "    tcount = 0    \n",
    "    while tcount < 10:  \n",
    "        youtube_dict ={}\n",
    "        # extract comment section of top ten links\n",
    "        url = href[tcount]\n",
    "        print (url)\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        try:\n",
    "            print(\"+\" * 40)  # Shows in terminal when details of a new video is being scraped\n",
    "            print(\"Scraping child links \")\n",
    "            #scroll down to load comments\n",
    "            driver.execute_script('window.scrollTo(0,390);')\n",
    "            time.sleep(15)\n",
    "            #sort by top comments\n",
    "            sort= driver.find_element_by_xpath(\"\"\"//*[@id=\"icon-label\"]\"\"\")\n",
    "            sort.click()\n",
    "            time.sleep(10)\n",
    "            topcomments =driver.find_element_by_xpath(\"\"\"//*[@id=\"menu\"]/a[1]/paper-item/paper-item-body/div[1]\"\"\")\n",
    "            topcomments.click()\n",
    "            time.sleep(10)\n",
    "            # Loads 20 comments , scroll two times to load next set of 40 comments. \n",
    "            for i in range(0,2):\n",
    "                driver.execute_script(\"window.scrollTo(0,Math.max(document.documentElement.scrollHeight,document.body.scrollHeight,document.documentElement.clientHeight))\")\n",
    "                time.sleep(10)\n",
    "            \n",
    "            #count total number of comments and set index to number of comments if less than 50 otherwise set as 50. \n",
    "            totalcomments= len(driver.find_elements_by_xpath(\"\"\"//*[@id=\"content-text\"]\"\"\"))\n",
    "         \n",
    "            if totalcomments < 50:\n",
    "                index= totalcomments\n",
    "            else:\n",
    "                index= 50 \n",
    "                \n",
    "            ccount = 0\n",
    "            while ccount < index: \n",
    "                try:\n",
    "                    comment = driver.find_elements_by_xpath('//*[@id=\"content-text\"]')[ccount].text\n",
    "                except:\n",
    "                    comment = \"\"\n",
    "                try:\n",
    "                    authors = driver.find_elements_by_xpath('//a[@id=\"author-text\"]/span')[ccount].text\n",
    "                except:\n",
    "                    authors = \"\"\n",
    "                try:\n",
    "                    comment_posted = driver.find_elements_by_xpath('//*[@id=\"published-time-text\"]/a')[ccount].text\n",
    "                except:\n",
    "                    comment_posted = \"\"\n",
    "                try:\n",
    "                    replies = driver.find_elements_by_xpath('//*[@id=\"more-text\"]')[ccount].text                    \n",
    "                    if replies ==\"View reply\":\n",
    "                        replies= 1\n",
    "                    else:\n",
    "                        replies =replies.replace(\"View \",\"\")\n",
    "                        replies =replies.replace(\" replies\",\"\")\n",
    "                except:\n",
    "                    replies = \"\"\n",
    "                try:\n",
    "                    upvotes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')[ccount].text\n",
    "                except:\n",
    "                    upvotes = \"\"\n",
    "                        \n",
    "                youtube_dict['url'] = href[tcount]\n",
    "                youtube_dict['link_title'] = title[tcount]\n",
    "                youtube_dict['channel'] = channel[tcount]\n",
    "                youtube_dict['no_of_views'] = numview[tcount]\n",
    "                youtube_dict['time_uploaded'] =  postdate[tcount]\n",
    "                youtube_dict['comment'] = comment\n",
    "                youtube_dict['author'] = authors\n",
    "                youtube_dict['comment_posted'] = comment_posted\n",
    "                youtube_dict['no_of_replies'] = replies\n",
    "                youtube_dict['upvotes'] = upvotes\n",
    "                \n",
    "                writer.writerow(youtube_dict.values())\n",
    "                ccount = ccount +1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.close()\n",
    "        tcount = tcount +1 \n",
    "    print(\"Scrapping process Completed\")   \n",
    "    csv_file.close()    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION-7\n",
    "url_2=\"https://www.digit.in/search/?keyword=gaming%20laptops\"\n",
    "driver.get(\"https://www.digit.in/search/?keyword=gaming%20laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "brand=[]\n",
    "Release_Date=[]\n",
    "price=[]\n",
    "updated_on=[]\n",
    "Availablity=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Brand\n",
    "Brand=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Brand:\n",
    "    if i.text is None :\n",
    "        brand.append(\"--\") \n",
    "    else:\n",
    "        brand.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Price\n",
    "Price=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Price:\n",
    "    if i.text is None :\n",
    "        price.append(\"--\") \n",
    "    else:\n",
    "        price.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the release_Date\n",
    "release_Date=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in release_Date:\n",
    "    if i.text is None :\n",
    "        Release_Date.append(\"--\") \n",
    "    else:\n",
    "        Release_Date.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Updated_on\n",
    "Updated_on=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Updated_on:\n",
    "    if i.text is None :\n",
    "        updated_on.append(\"--\") \n",
    "    else:\n",
    "        updated_on.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the availablity\n",
    "availablity=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in availablity:\n",
    "    if i.text is None :\n",
    "        Availablity.append(\"--\") \n",
    "    else:\n",
    "        Availablity.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "brand=[]\n",
    "Release_Date=[]\n",
    "price=[]\n",
    "updated_on=[]\n",
    "Availablity=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'brand':brand[:100],'Release_Date':Release_Date[:100],'price': price[:100],'updated_on':updated_on[:100],'country': country[:100],'Availablity':Availablity[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape a data for all available Hostels from \n",
    "https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, \n",
    "distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms \n",
    "from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.hostelworld.com/s?q=London,%20England&city=London&country=England&type=city&id=3&from=2021-08-24&to=2021-08-30&guests=2&page=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.hostelworld.com/s?q=London,%20England&city=London&country=England&type=city&id=3&from=2021-08-24&to=2021-08-30&guests=2&page=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city centre, ratings, total reviews, overall reviews, privates from price, dorms \n",
    "from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location.send_keys(\"London\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "city centre=[]\n",
    "ratings=[]\n",
    "total reviews=[]\n",
    "overall reviews=[]\n",
    "facilities=[]\n",
    "property_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the City_centre\n",
    "City_centre=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in City_centre:\n",
    "    if i.text is None :\n",
    "        city_centre.append(\"--\") \n",
    "    else:\n",
    "        city_centre.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Ratings\n",
    "Ratings=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Ratings:\n",
    "    if i.text is None :\n",
    "        ratings.append(\"--\") \n",
    "    else:\n",
    "        ratings.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Total reviews\n",
    "Total reviews=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Total reviews:\n",
    "    if i.text is None :\n",
    "        total reviews.append(\"--\") \n",
    "    else:\n",
    "        total reviews.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Overall reviews\n",
    "Overall reviews=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Overall reviews:\n",
    "    if i.text is None :\n",
    "        overall reviews.append(\"--\") \n",
    "    else:\n",
    "        overall reviews.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Facilities\n",
    "Facilities=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Facilities:\n",
    "    if i.text is None :\n",
    "        facilities.append(\"--\") \n",
    "    else:\n",
    "        facilities.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Property_description\n",
    "Property_description=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Property_description:\n",
    "    if i.text is None :\n",
    "        property_description.append(\"--\") \n",
    "    else:\n",
    "        property_description.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "city centre=[]\n",
    "ratings=[]\n",
    "total reviews=[]\n",
    "overall reviews=[]\n",
    "facilities=[]\n",
    "property description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'city centre':city centre[:100],'ratings':ratings[:100],'total reviews': total reviews[:100],'overall reviews':overall reviews[:100],'facilities': facilities[:100],'property description':property description[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –\n",
    "September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://trak.in/?s=July+20+%E2%80%93+September+20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://trak.in/?s=July+20+%E2%80%93+September+20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "title=[]\n",
    "author=[]\n",
    "date=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the title\n",
    "Title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Title:\n",
    "    if i.text is None :\n",
    "        title.append(\"--\") \n",
    "    else:\n",
    "        title.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "Author=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Author:\n",
    "    if i.text is None :\n",
    "        author.append(\"--\") \n",
    "    else:\n",
    "        author.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "Date=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Date:\n",
    "    if i.text is None :\n",
    "        date.append(\"--\") \n",
    "    else:\n",
    "        date.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "title=[]\n",
    "author=[]\n",
    "date=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'title':title[:100],'author':author[:100],'date': date[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on \n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, \n",
    "“Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display \n",
    "Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. \n",
    "Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe \n",
    "and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/search?q=%2C%20pixel%204A%2C&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/search?q=%2C%20pixel%204A%2C&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Brand Name=[]\n",
    "Smartphone name=[]\n",
    "RAM=[]\n",
    "Storage(ROM)=[]\n",
    "Primary Camera=[]\n",
    "Secondary Camera=[]\n",
    "Display Size=[]\n",
    "Display=[]\n",
    "Processor=[]\n",
    "Processor Cores=[]\n",
    "Battery Capacity=[]\n",
    "Price=[]\n",
    "Product URL=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " “Brand Name”, “Smartphone name”, “Smartphone name”, “RAM”, \n",
    "“Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display \n",
    "Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the brand Name\n",
    "brand Name=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in brand Name:\n",
    "    if i.text is None :\n",
    "        Brand Name.append(\"--\") \n",
    "    else:\n",
    "        Brand Name.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the smartphone name\n",
    "smartphone name=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in smartphone name:\n",
    "    if i.text is None :\n",
    "        Smartphone name.append(\"--\") \n",
    "    else:\n",
    "        Smartphone name.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the rAM\n",
    "rAM=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in rAM:\n",
    "    if i.text is None :\n",
    "        RAM.append(\"--\") \n",
    "    else:\n",
    "        RAM.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the storage(ROM)\n",
    "storage(ROM)=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in storage(ROM):\n",
    "    if i.text is None :\n",
    "        Storage(ROM).append(\"--\") \n",
    "    else:\n",
    "        Storage(ROM).append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the primary Camera\n",
    "primary Camera=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in primary Camera:\n",
    "    if i.text is None :\n",
    "        Primary Camera.append(\"--\") \n",
    "    else:\n",
    "        Primary Camera.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the secondary Camera\n",
    "secondary_Camera=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in secondary_Camera:\n",
    "    if i.text is None :\n",
    "        Secondary_Camera.append(\"--\") \n",
    "    else:\n",
    "        Secondary_Camera.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the display_Size\n",
    "display_Size=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in display_Size:\n",
    "    if i.text is None :\n",
    "        Display_Size.append(\"--\") \n",
    "    else:\n",
    "        Display_Size.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the display\n",
    "display=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in display:\n",
    "    if i.text is None :\n",
    "        Display.append(\"--\") \n",
    "    else:\n",
    "        Display.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the processor\n",
    "processor=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in processor:\n",
    "    if i.text is None :\n",
    "        Processor.append(\"--\") \n",
    "    else:\n",
    "        Processor.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Processor_Cores\n",
    "Processor_Cores=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Processor_Cores:\n",
    "    if i.text is None :\n",
    "        Processor_Cores.append(\"--\") \n",
    "    else:\n",
    "        Processor_Cores.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Battery_Capacity\n",
    "Battery_Capacity=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in Battery_Capacity:\n",
    "    if i.text is None :\n",
    "        Battery_Capacity.append(\"--\") \n",
    "    else:\n",
    "        Battery_Capacity.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the price\n",
    "price=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in price:\n",
    "    if i.text is None :\n",
    "        Price.append(\"--\") \n",
    "    else:\n",
    "        Price.append(i.text)\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the product URL\n",
    "product URL=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in product URL:\n",
    "    if i.text is None :\n",
    "        Product URL.append(\"--\") \n",
    "    else:\n",
    "        Product URL.append(i.get_attribute('href'))\n",
    "\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Brand Name=[]\n",
    "Smartphone name=[]\n",
    "RAM=[]\n",
    "Storage(ROM)=[]\n",
    "Primary Camera=[]\n",
    "Secondary Camera=[]\n",
    "Display Size=[]\n",
    "Display=[]\n",
    "Processor=[]\n",
    "Processor Cores=[]\n",
    "Battery Capacity=[]\n",
    "Price=[]\n",
    "Product URL=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Brand Name':Brand Name[:100],'Smartphone name':Smartphone name[:100],'RAM': RAM[:100],'Storage(ROM)':Storage(ROM)[:100],'Primary Camera':Primary Camera[:100],'Secondary Camera': Secondary Camera[:100],'Display Size':Display Size,'Display':Display,'Processor':Processor,'Processor Cores':Processor Cores,'Battery Capacity':Battery Capacity,'Price':Price,'Product URL':Product URL})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
